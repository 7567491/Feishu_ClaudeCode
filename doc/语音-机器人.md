# 飞书语音转文字机器人实现方案分析

## 背景

当前项目已实现基于飞书 WebSocket 的机器人，支持文本消息、文件消息、图片消息等多种消息类型处理。现需要增加语音消息处理能力：用户在飞书对话里发送语音，系统自动将语音转成文字，再传递给 Claude 进行处理。

## 当前架构分析

### 现有消息处理流程

```
飞书用户 → WebSocket 事件推送 → FeishuClient.handleMessageEvent()
         → 消息类型判断 (text/file/image/media)
         → FeishuService.handleMessage()
         → Claude 处理
         → 飞书响应
```

**代码位置：**
- 主服务：`server/feishu-ws.js` (FeishuService)
- 飞书客户端：`server/lib/feishu-client.js` (FeishuClient)
- 消息类型处理：`feishu-client.js:146-160` (file/image/media 分支)

**当前支持的消息类型：**
- `text` - 文本消息
- `file` - 文件上传
- `image` - 图片上传
- `media` - 媒体文件

**当前不支持：**
- `audio` - 语音消息（未实现）

## 三种实现方案对比

### 方案一：飞书原生语音识别 + 文本消息回调

**原理：**
利用飞书客户端自带的语音转文字功能。用户在飞书手机端发送语音时，飞书会自动将语音转成文字并显示，机器人直接接收转写后的文本。

**实现方式：**
1. 在飞书开放平台配置"语音消息识别"权限
2. 用户发送语音消息 → 飞书自动转写 → 事件推送包含 `text` 字段
3. 机器人接收事件时检查 `message_type` 是否为 `audio`，但内容中已包含转写文本
4. 直接使用转写文本调用 Claude

**代码改动（最小）：**
```javascript
// server/lib/feishu-client.js
async handleMessageEvent(data) {
  const msgType = event.message?.message_type;

  // 新增：处理语音消息
  if (msgType === 'audio') {
    const parsedContent = JSON.parse(content);
    const transcribedText = parsedContent.text || parsedContent.transcript;

    if (transcribedText) {
      // 直接使用转写文本
      await this.messageHandler(event, transcribedText.trim(), null);
      return;
    }
  }

  // 原有的 file/image/text 处理逻辑...
}
```

**优势：**
- ✅ **实现最简单**：飞书已做转写，机器人只需接收文本
- ✅ **零额外成本**：无需调用第三方语音识别 API
- ✅ **用户体验好**：飞书客户端直接显示转写文本，用户可确认准确性
- ✅ **代码改动最小**：只需在现有消息处理逻辑中增加 `audio` 类型分支（约 10 行代码）
- ✅ **无需下载音频**：不需要处理音频文件的下载、存储、格式转换

**劣势：**
- ⚠️ **依赖飞书客户端**：仅限手机端且用户需主动选择"发送为语音消息"（而非录音文件）
- ⚠️ **识别准确性受限**：依赖飞书内置识别引擎（支持中文、英语、日语），无法自定义
- ⚠️ **可能的权限问题**：需确认当前飞书应用是否有 `im:message.audio` 权限

**适用场景：**
- 用户主要使用飞书手机端发送快捷语音（而非录音文件）
- 对识别准确性要求不高，能接受飞书内置识别引擎
- 追求最快上线速度

---

### 方案二：飞书语音识别 API（官方 ASR）

**原理：**
使用飞书开放平台提供的语音识别 API（Automatic Speech Recognition），将语音文件转成文字。

**实现方式：**
1. 监听 `audio` 类型消息事件
2. 从事件中提取 `file_key` 和 `message_id`
3. 下载音频文件（调用飞书 `im.file.get` API）
4. 调用飞书 ASR API：
   - 文件识别：`POST https://open.feishu.cn/open-apis/speech_to_text/v1/speech/file_recognize`
   - 流式识别：`POST https://open.feishu.cn/open-apis/speech_to_text/v1/speech/stream_recognize`
5. 获取转写文本，传递给 Claude

**代码改动（中等）：**
```javascript
// server/lib/feishu-client.js
/**
 * 下载音频文件
 */
async downloadAudioFile(messageId, fileKey) {
  const res = await this.client.im.file.get({
    path: { message_id: messageId, file_key: fileKey }
  });
  return res.file; // 返回音频 buffer
}

/**
 * 调用飞书 ASR API
 */
async recognizeAudio(audioBuffer) {
  const res = await this.client.request({
    method: 'POST',
    url: '/open-apis/speech_to_text/v1/speech/file_recognize',
    data: {
      speech: {
        speech: audioBuffer.toString('base64'),
        format: 'pcm',  // 或 m4a/opus 等
        engine_type: 'model_16k'
      },
      config: {
        language: 'zh_cn'  // 中文识别
      }
    }
  });
  return res.data.recognition_text;
}

// 在 handleMessageEvent 中处理 audio 类型
if (msgType === 'audio') {
  const parsedContent = JSON.parse(content);
  const fileKey = parsedContent.file_key;
  const messageId = event.message.message_id;

  // 下载音频
  const audioBuffer = await this.downloadAudioFile(messageId, fileKey);

  // 识别语音
  const transcribedText = await this.recognizeAudio(audioBuffer);

  // 传递给 Claude
  await this.messageHandler(event, transcribedText, null);
}
```

**优势：**
- ✅ **官方支持**：飞书官方提供的 API，稳定可靠
- ✅ **支持多种音频格式**：PCM、WAV、OPUS、SPEEX、FLAC、AMR、M4A 等
- ✅ **准确性较高**：支持中文、英文、日文识别，模型质量有保障
- ✅ **无需第三方服务**：完全在飞书生态内完成，减少外部依赖

**劣势：**
- ⚠️ **需要额外权限**：需申请 `speech:speech.file_recognize` 权限（可能需要企业认证）
- ⚠️ **实现复杂度较高**：需要处理音频下载、格式判断、API 调用、错误重试
- ⚠️ **可能有配额限制**：飞书 ASR API 可能存在调用频率限制（需查看文档）
- ⚠️ **异步处理**：文件识别是异步接口，需要轮询或等待结果

**技术难点：**
1. 音频格式适配（飞书录音可能是 AMR/OPUS 等移动端格式）
2. 大文件处理（语音可能较长，需考虑超时和分片）
3. 错误处理（识别失败、无语音内容等边界情况）

**适用场景：**
- 对识别准确性有较高要求
- 需要支持桌面端录音文件上传
- 希望完全在飞书生态内完成，避免外部依赖

---

### 方案三：第三方语音识别服务（如阿里云/腾讯云）

**原理：**
使用成熟的第三方 ASR 服务（如阿里云智能语音、腾讯云 ASR、科大讯飞等）进行语音识别。

**实现方式：**
1. 监听 `audio` 类型消息事件
2. 从飞书下载音频文件（同方案二）
3. 将音频文件上传到第三方 ASR 服务
4. 获取识别结果，传递给 Claude

**代码改动（较大）：**
```javascript
// server/lib/asr-client.js（新增文件）
import AlibabaCloud from '@alicloud/alinlp20200629'; // 示例：阿里云

export class ASRClient {
  constructor(config) {
    this.client = new AlibabaCloud({
      accessKeyId: config.accessKeyId,
      accessKeySecret: config.accessKeySecret,
      endpoint: 'nls-meta.cn-shanghai.aliyuncs.com'
    });
  }

  async recognizeAudio(audioBuffer, format = 'pcm') {
    const res = await this.client.recognizeFile({
      fileUrl: this.uploadToOSS(audioBuffer), // 先上传到 OSS
      format: format,
      sampleRate: 16000,
      enablePunctuation: true
    });
    return res.result;
  }

  // 上传音频到 OSS
  async uploadToOSS(audioBuffer) {
    // OSS 上传逻辑...
  }
}

// server/lib/feishu-client.js
import { ASRClient } from './asr-client.js';

// 在 handleMessageEvent 中
if (msgType === 'audio') {
  const audioBuffer = await this.downloadAudioFile(messageId, fileKey);

  // 使用第三方 ASR
  const asrClient = new ASRClient(config);
  const transcribedText = await asrClient.recognizeAudio(audioBuffer);

  await this.messageHandler(event, transcribedText, null);
}
```

**优势：**
- ✅ **识别准确度最高**：专业 ASR 服务，支持方言、垂直领域优化
- ✅ **功能丰富**：支持关键词识别、语气词过滤、智能断句、说话人分离等高级功能
- ✅ **可定制化**：可针对特定场景训练自定义模型
- ✅ **技术支持完善**：大厂提供技术支持和 SLA 保障

**劣势：**
- ❌ **额外成本**：按调用次数或时长收费（例如阿里云：0.025元/分钟）
- ❌ **增加外部依赖**：需要注册第三方服务、管理 API 密钥
- ❌ **实现复杂度最高**：需要处理音频上传、格式转换、服务集成、账户管理
- ❌ **数据隐私风险**：音频文件会上传到第三方服务器（可能涉及用户隐私）
- ❌ **网络延迟**：音频需上传到外部服务，识别耗时较长

**成本估算（以阿里云为例）：**
- 录音时长平均 30 秒/条
- 日均 1000 条语音消息
- 成本：(1000 * 0.5分钟) * 0.025元 = 12.5元/天 ≈ 375元/月

**适用场景：**
- 对识别准确性要求极高（如客服场景、医疗场景）
- 需要处理方言或专业术语
- 预算充足，可接受外部服务成本

---

## 综合对比表

| 维度 | 方案一：飞书原生转写 | 方案二：飞书 ASR API | 方案三：第三方 ASR |
|------|---------------------|---------------------|-------------------|
| **实现难度** | ⭐ 极简（10 行代码） | ⭐⭐⭐ 中等（~100 行） | ⭐⭐⭐⭐⭐ 复杂（~300 行） |
| **开发周期** | 0.5 天 | 2-3 天 | 5-7 天 |
| **额外成本** | 免费 | 免费（可能有配额） | 按量收费（375元/月） |
| **识别准确性** | ⭐⭐⭐ 中等 | ⭐⭐⭐⭐ 较高 | ⭐⭐⭐⭐⭐ 极高 |
| **支持语言** | 中英日 | 中英日 | 全球主流语言 + 方言 |
| **处理速度** | 即时（飞书已转写） | 3-10 秒 | 5-15 秒 |
| **外部依赖** | 无 | 无 | 有（阿里云/腾讯云） |
| **数据隐私** | ✅ 飞书内部 | ✅ 飞书内部 | ⚠️ 上传第三方 |
| **权限要求** | `im:message.audio` | `speech:speech.file_recognize` | 无（仅需飞书消息权限） |
| **高级功能** | 无 | 基础转写 | 关键词/情绪/说话人分离 |
| **维护成本** | 极低 | 中等 | 高（账户/密钥管理） |

---

## 推荐方案

### 🥇 首选：方案一（飞书原生语音转写）

**推荐理由：**
1. **符合"用最简单的方法完成任务"原则**（CLAUDE.md 第 9 行）
2. **最小改动原则**：只需在现有消息处理逻辑中增加 1 个分支
3. **零成本**：无需额外付费服务
4. **快速验证**：0.5 天即可上线，快速验证用户需求
5. **用户体验好**：飞书客户端已显示转写文本，用户可先确认准确性

**实施步骤：**
1. 检查飞书应用权限是否包含 `im:message.audio`
2. 在 `feishu-client.js:145` 后增加 `audio` 分支处理
3. 测试：手机端发送语音，验证机器人能接收转写文本
4. 监控日志，观察 `message_type` 和 `content` 结构

**风险控制：**
- 如果飞书不提供转写文本（需实测验证），可快速切换到方案二
- 如果识别准确性不够，可后续升级到方案三

### 🥈 备选：方案二（飞书 ASR API）

**适用条件：**
- 方案一测试后发现飞书不提供转写文本字段
- 或用户需要支持桌面端上传录音文件

**前置工作：**
- 先在飞书开放平台申请 `speech:speech.file_recognize` 权限
- 阅读官方文档，确认 API 调用配额和限制

### 🥉 不推荐：方案三（第三方 ASR）

**原因：**
- 违反"不过度工程化"原则
- 增加外部依赖和成本
- 除非业务场景明确需要高级功能（如方言识别、情绪分析），否则不建议采用

---

## 实施计划（方案一）

### Phase 1：验证飞书语音消息结构（0.5 小时）

```bash
# 1. 启动飞书服务，打开详细日志
cd /home/ccp
pm2 logs feishu --lines 100

# 2. 在飞书测试群发送语音消息
# 3. 观察日志中的 message_type 和 content 结构
```

**预期日志：**
```
[FeishuClient] Message Type: audio
[FeishuClient] Raw event data: {
  "message": {
    "message_type": "audio",
    "content": "{\"file_key\":\"...\", \"text\":\"转写文本\"}"
  }
}
```

### Phase 2：代码实现（1 小时）

```javascript
// server/lib/feishu-client.js:145 后增加

// 处理语音消息
if (msgType === 'audio') {
  console.log('[FeishuClient] Audio message detected');

  const parsedContent = JSON.parse(content);
  const transcribedText = parsedContent.text || parsedContent.transcript || parsedContent.recognition_text;

  if (transcribedText) {
    console.log('[FeishuClient] Transcribed text:', transcribedText);
    await this.messageHandler(event, transcribedText.trim(), null);
    return;
  } else {
    console.warn('[FeishuClient] No transcribed text found in audio message');
    // 可选：发送提示消息
    await this.sendTextMessage(
      event.message.chat_id,
      '⚠️ 未能识别语音内容，请尝试重新发送或使用文字消息'
    );
    return;
  }
}
```

### Phase 3：测试验证（1 小时）

1. **单元测试**：构造 `audio` 类型事件，验证处理逻辑
2. **集成测试**：
   - 私聊发送语音 → 验证机器人响应
   - 群聊发送语音 → 验证@机器人后响应
   - 长语音（>30秒）→ 验证处理稳定性
3. **边界测试**：
   - 无声语音
   - 噪音语音
   - 多语言混合

### Phase 4：监控和优化（持续）

```javascript
// 增加统计日志
feishuDb.logMessage(
  session.id,
  'incoming',
  'audio',
  `voice:${transcribedText.substring(0, 50)}...`, // 记录转写文本前 50 字符
  event.message?.message_id
);
```

---

## 技术文档参考

**飞书开放平台：**
- [飞书妙记 - 语音识别转文字](https://www.feishu.cn/product/minutes)
- [语音转文字文档](https://blog.csdn.net/STR_Liang/article/details/117517986)
- [发送语音消息](https://www.feishu.cn/hc/zh-CN/articles/360039394633)

**飞书 API 文档：**
- [Audio file speech recognition](https://open.feishu.cn/document/uAjLw4CM/ukTMukTMukTM/reference/ai/speech_to_text-v1/speech/file_recognize)
- [Streaming speech recognition](https://open.feishu.cn/document/uAjLw4CM/ukTMukTMukTM/reference/ai/speech_to_text-v1/speech/stream_recognize)
- [Send message content structure](https://open.feishu.cn/document/server-docs/im-v1/message-content-description/create_json)
- [Obtain resource files in messages](https://open.feishu.cn/document/server-docs/im-v1/message/get-2)

**SDK 文档：**
- [Lark Node.js SDK](https://www.npmjs.com/package/@larksuiteoapi/node-sdk)
- [go-lark SDK](https://github.com/go-lark/lark)

---

## 附录：示例代码（完整实现）

### A. 方案一实现（推荐）

```javascript
// server/lib/feishu-client.js
async handleMessageEvent(data) {
  try {
    const event = data.event || data;
    const msgType = event.message?.message_type;
    const content = event.message?.content;

    if (!content) return;

    let parsedContent;
    try {
      parsedContent = JSON.parse(content);
    } catch (error) {
      console.error('[FeishuClient] Failed to parse message content:', error.message);
      return;
    }

    // 🆕 处理语音消息
    if (msgType === 'audio') {
      console.log('[FeishuClient] Audio message detected');

      // 尝试多种可能的转写文本字段名
      const transcribedText = parsedContent.text
        || parsedContent.transcript
        || parsedContent.recognition_text
        || parsedContent.content;

      if (transcribedText && transcribedText.trim()) {
        console.log('[FeishuClient] Voice transcribed:', transcribedText);

        // 传递给消息处理器（与文本消息相同流程）
        if (this.messageHandler) {
          await this.messageHandler(event, transcribedText.trim(), null);
        }
        return;
      } else {
        console.warn('[FeishuClient] No transcription found in audio message');
        console.warn('[FeishuClient] Audio content structure:', parsedContent);

        // 友好提示用户
        const chatId = event.message?.chat_id;
        if (chatId) {
          await this.sendTextMessage(
            chatId,
            '⚠️ 抱歉，未能识别您的语音内容。请尝试：\n' +
            '1. 重新清晰地说一遍\n' +
            '2. 或直接发送文字消息'
          );
        }
        return;
      }
    }

    // 原有的 file/image/media 处理逻辑
    if (msgType === 'file' || msgType === 'image' || msgType === 'media') {
      // ... 现有代码 ...
    }

    // 原有的 text 处理逻辑
    // ... 现有代码 ...

  } catch (error) {
    console.error('[FeishuClient] Error handling message:', error.message);
    console.error(error.stack);
  }
}
```

### B. 测试用例

```javascript
// server/tests/feishu-audio.test.js
import { FeishuClient } from '../lib/feishu-client.js';

describe('Audio Message Handling', () => {
  let client;

  beforeEach(() => {
    client = new FeishuClient({
      appId: 'test_app_id',
      appSecret: 'test_app_secret'
    });
  });

  test('should handle audio message with transcribed text', async () => {
    const mockEvent = {
      message: {
        message_type: 'audio',
        chat_id: 'ou_test123',
        message_id: 'om_test456',
        content: JSON.stringify({
          file_key: 'file_v2_xxx',
          text: '你好，请帮我查询今天的天气'
        })
      }
    };

    const mockHandler = jest.fn();
    client.messageHandler = mockHandler;

    await client.handleMessageEvent(mockEvent);

    expect(mockHandler).toHaveBeenCalledWith(
      mockEvent,
      '你好，请帮我查询今天的天气',
      null
    );
  });

  test('should send warning when no transcription available', async () => {
    const mockEvent = {
      message: {
        message_type: 'audio',
        chat_id: 'ou_test123',
        content: JSON.stringify({
          file_key: 'file_v2_xxx'
          // 缺少 text 字段
        })
      }
    };

    const sendTextSpy = jest.spyOn(client, 'sendTextMessage');

    await client.handleMessageEvent(mockEvent);

    expect(sendTextSpy).toHaveBeenCalledWith(
      'ou_test123',
      expect.stringContaining('未能识别')
    );
  });
});
```

---

## 结论

**最优方案：方案一（飞书原生语音转写）**

- 符合"用最简单的方法完成任务"的项目原则
- 最小改动、最快上线、零成本、零外部依赖
- 如果后续需求升级，可平滑过渡到方案二或方案三

**下一步行动：**
1. 先在测试环境验证飞书语音消息的 `content` 结构（**关键验证点**）
2. 如果飞书提供转写文本，立即实施方案一（0.5 天上线）
3. 如果飞书不提供转写文本，准备实施方案二（3 天上线）
4. 方案三仅在明确需要高级功能时考虑

**风险提示：**
- 方案一的可行性依赖于飞书是否在 WebSocket 事件中提供转写文本（需实测验证）
- 如果飞书只在客户端显示转写但不推送给机器人，需切换到方案二
